{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import random\n",
    "import pingouin as pg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy import io\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "import nibabel as nib\n",
    "from scipy.linalg import pinv, pinv2\n",
    "from statannot import add_stat_annotation\n",
    "from statsmodels import robust\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import math\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import skew, skewtest\n",
    "from sklearn.metrics import explained_variance_score, r2_score\n",
    "from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topdir = '/users/jsh/data/IG/ICA/2023-04-25/pca_ref/result_nucleus/30'\n",
    "sbj_list = pd.read_csv(topdir + '/first_para_ica_sel_data.txt', header = None)\n",
    "sbj_list.columns = ['temp']\n",
    "sbj_list = sbj_list.loc[0:len(sbj_list)/2]\n",
    "sbj_list['sbj'] = sbj_list.temp.str.split('/').str[9]\n",
    "sbj_list['case'] = sbj_list.temp.str.split('/').str[8]\n",
    "sbj_list = sbj_list.dropna(axis = 0)\n",
    "sbj_info = sbj_list[['sbj', 'case']]\n",
    "\n",
    "# sbj_info\n",
    "sbjlist = []\n",
    "\n",
    "for i in sbj_info['sbj'].tolist():\n",
    "    sbjlist.append(i[:4]+'_'+i[4:])\n",
    "\n",
    "demo = pd.read_csv('/users/jsh/data/IG/Demographic+Behavior/abcd_sst02.txt', sep = '\\t')\n",
    "demo = demo.loc[demo['subjectkey'].isin(sbjlist)]\n",
    "demo = demo.loc[demo['eventname'] == 'baseline_year_1_arm_1']\n",
    "\n",
    "scanner = pd.read_csv('/users/jsh/data/IG/Demographic+Behavior/abcd_mri01.txt', sep = '\\t')\n",
    "scanner = scanner.loc[scanner['subjectkey'].isin(sbjlist)]\n",
    "\n",
    "demo_scanner = pd.merge(demo, scanner, on = 'subjectkey')\n",
    "demo_exclude = demo_scanner[['subjectkey', 'interview_age_x', 'sex', 'mri_info_manufacturer']]\n",
    "\n",
    "# handness\n",
    "temp = pd.read_csv('/users/jsh/data/IG/Demographic+Behavior/abcd_ehis01.txt', sep = '\\t')\n",
    "temp = temp[['subjectkey', 'ehi_y_ss_scoreb']]\n",
    "demo_exclude = pd.merge(demo_exclude, temp)\n",
    "\n",
    "demo_exclude['ehi_y_ss_scoreb'] = demo_exclude['ehi_y_ss_scoreb'].astype(float)\n",
    "\n",
    "# Genetic batch effect\n",
    "\n",
    "batch = pd.read_csv('/data5/open_data/ABCD/3.0/genomics_sample03/ABCD_release3.0_.batch_info.txt', sep = '\\t')\n",
    "batch = batch[['abcd.id_redcap', 'BATCH']]\n",
    "batch.columns = ['subjectkey', 'BATCH']\n",
    "demo_exclude = pd.merge(demo_exclude, batch)\n",
    "\n",
    "\n",
    "basedir = '/users/jsh/data/IG/ICA/2023-04-25/input_origin'\n",
    "control_dir = basedir + '/control'\n",
    "ADHD_dir = basedir + '/ADHD'\n",
    "\n",
    "control_subjects = os.listdir(control_dir)\n",
    "ADHD_subjects = os.listdir(ADHD_dir)\n",
    "\n",
    "both_run = []\n",
    "run1 = []\n",
    "run2 = []\n",
    "\n",
    "for i in control_subjects:\n",
    "    targetdir = control_dir + '/' + i + '/fMRI'\n",
    "    if 'con_not_masked1.nii' and 'con_not_masked2.nii' in os.listdir(targetdir):\n",
    "        both_run.append(i[:4] + '_' + i[4:])\n",
    "    elif 'con_not_masked1.nii' in os.listdir(targetdir):\n",
    "        run1.append(i[:4] + '_' + i[4:])\n",
    "    elif 'con_not_masked2.nii' in os.listdir(targetdir):\n",
    "        run2.append(i[:4] + '_' + i[4:])\n",
    "        \n",
    "for i in ADHD_subjects:\n",
    "    targetdir = ADHD_dir + '/' + i + '/fMRI'\n",
    "    if 'con_not_masked1.nii' and 'con_not_masked2.nii' in os.listdir(targetdir):\n",
    "        both_run.append(i[:4] + '_' + i[4:])\n",
    "    elif 'con_not_masked1.nii' in os.listdir(targetdir):\n",
    "        run1.append(i[:4] + '_' + i[4:])\n",
    "    elif 'con_not_masked2.nii' in os.listdir(targetdir):\n",
    "        run2.append(i[:4] + '_' + i[4:])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/users/jsh/data/IG/Demographic+Behavior/abcd_sst02.txt', sep = '\\t')\n",
    "\n",
    "data = data.drop(['collection_id', 'abcd_sst02_id', 'dataset_id', 'src_subject_id', 'interview_date', 'collection_title'], axis = 1)\n",
    "data = data.loc[data['eventname'] == 'baseline_year_1_arm_1']\n",
    "data = data.drop(['eventname'], axis = 1)\n",
    "\n",
    "sbj_list = pd.read_csv('/users/jsh/data/IG/ICA/2023-04-25/pca_ref/result_nucleus/30/first_para_ica_sel_data.txt', header = None)\n",
    "sbj_list.columns = ['temp']\n",
    "sbj_list = sbj_list.loc[0:len(sbj_list)/2]\n",
    "sbj_list['sbj'] = sbj_list.temp.str.split('/').str[9]\n",
    "sbj_list['case'] = sbj_list.temp.str.split('/').str[8]\n",
    "sbj_list = sbj_list.dropna(axis = 0)\n",
    "sbj_info = sbj_list[['sbj', 'case']]\n",
    "\n",
    "temp = []\n",
    "\n",
    "for i in sbj_info['sbj']:\n",
    "    temp.append(i[:4] + '_' + i[4:])\n",
    "    \n",
    "sbj_info['subjectkey'] = temp\n",
    "data_merged = pd.merge(sbj_info, data, how = 'inner', on = 'subjectkey')\n",
    "\n",
    "\n",
    "coeff = io.loadmat('/users/jsh/data/IG/ICA/2023-04-25/pca_ref/result_nucleus/30/first_para_ica_ica.mat')\n",
    "fMRI_A_origin = coeff['loadingCoeff'][0][0]\n",
    "Gene_A_origin = coeff['loadingCoeff'][0][1]\n",
    "\n",
    "fMRI_A_origin = pd.DataFrame(fMRI_A_origin)\n",
    "Gene_A_origin = pd.DataFrame(Gene_A_origin)\n",
    "\n",
    "data_merged['fMRI'] = fMRI_A_origin[14 - 1]\n",
    "data_merged['Gene'] = Gene_A_origin[21 - 1]\n",
    "\n",
    "data_merged.loc[data_merged['subjectkey'].isin(run1), 'tfmri_sst_all_beh_crgo_rt'] = data_merged[data_merged['subjectkey'].isin(run1)]['tfmri_sst_r1_beh_crgo_rt'].tolist()\n",
    "data_merged.loc[data_merged['subjectkey'].isin(run1), 'tfmri_sst_all_beh_crgo_mrt'] = data_merged[data_merged['subjectkey'].isin(run1)]['tfmri_sst_r1_beh_crgo_mrt'].tolist()\n",
    "data_merged.loc[data_merged['subjectkey'].isin(run1), 'tfmri_sst_all_beh_incrs_mrt'] = data_merged[data_merged['subjectkey'].isin(run1)]['tfmri_sst_r1_beh_incrs_mrt'].tolist()\n",
    "data_merged.loc[data_merged['subjectkey'].isin(run1), 'tfmri_sst_all_beh_crgo_stdrt'] = data_merged[data_merged['subjectkey'].isin(run1)]['tfmri_sst_r1_beh_crgo_stdrt'].tolist()\n",
    "\n",
    "data_merged = data_merged.astype({'tfmri_sst_all_beh_crgo_rt':'float',\n",
    "                                 'tfmri_sst_all_beh_crgo_mrt':'float',\n",
    "                                 'tfmri_sst_all_beh_incrs_mrt':'float',\n",
    "                                 'tfmri_sst_all_beh_tot_mssd':'float',\n",
    "                                 'tfmri_sst_all_beh_total_mssrt':'float',\n",
    "                                 'tfmri_sst_all_beh_total_issrt':'float',\n",
    "                                 'tfmri_sst_all_beh_crgo_stdrt':'float',\n",
    "                                                                    \n",
    "                                 'tfmri_sst_all_beh_go_nt':'float',\n",
    "                                 'tfmri_sst_r1_beh_go_nt':'float',\n",
    "                                 'tfmri_sst_all_beh_crgo_nt':'float', # all correct go\n",
    "                                 'tfmri_sst_r1_beh_crgo_nt':'float', # r1 correct go\n",
    "                                 'tfmri_sst_all_beh_incrgo_nt':'float', # all incorrect go\n",
    "                                 'tfmri_sst_r1_beh_incrgo_nt':'float'}) # r1 incorrect go\n",
    "#\n",
    "data_final = pd.merge(data_merged, demo_exclude, on = 'subjectkey')\n",
    "\n",
    "data_final['interview_age'] = data_final['interview_age'].astype(float)\n",
    "\n",
    "data_final.loc[data_final['subjectkey'].isin(run1), 'tfmri_sst_all_beh_crgo_nt'] = data_final[data_final['subjectkey'].isin(run1)]['tfmri_sst_r1_beh_crgo_nt'].tolist()\n",
    "data_final.loc[data_final['subjectkey'].isin(run1), 'tfmri_sst_all_beh_incrgo_nt'] = data_final[data_final['subjectkey'].isin(run1)]['tfmri_sst_r1_beh_incrgo_nt'].tolist()\n",
    "\n",
    "data_final['ALL_MEAN_GORT'] = (data_final['tfmri_sst_all_beh_crgo_mrt'] * data_final['tfmri_sst_all_beh_crgo_nt'] + data_final['tfmri_sst_all_beh_incrs_mrt'] * data_final['tfmri_sst_all_beh_incrgo_nt']) / (data_final['tfmri_sst_all_beh_crgo_nt'] + data_final['tfmri_sst_all_beh_incrgo_nt'])\n",
    "data_final['ICE'] = data_final['tfmri_sst_all_beh_total_mssrt'] - data_final['tfmri_sst_all_beh_tot_mssd']\n",
    "\n",
    "iq = pd.read_csv('/users/jsh/data/IG/Demographic+Behavior/abcd_tbss01.txt', sep = '\\t')\n",
    "iq = iq[['subjectkey', 'nihtbx_totalcomp_uncorrected']]\n",
    "data_final = pd.merge(data_final, iq, on = 'subjectkey')\n",
    "data_final = data_final.astype({'nihtbx_totalcomp_uncorrected':'float'})\n",
    "data_final['sex'] = data_final['sex_x']\n",
    "\n",
    "data_final = data_final[['case', 'subjectkey', 'interview_age', 'sex', 'mri_info_manufacturer', 'BATCH', 'fMRI', 'Gene',\n",
    "                         'tfmri_sst_all_beh_crgo_rt', 'tfmri_sst_all_beh_crgo_mrt', 'tfmri_sst_all_beh_incrs_mrt',\n",
    "                         'tfmri_sst_all_beh_tot_mssd', 'tfmri_sst_all_beh_total_mssrt', \n",
    "                         'tfmri_sst_all_beh_total_issrt', 'tfmri_sst_all_beh_crgo_stdrt',\n",
    "                         'nihtbx_totalcomp_uncorrected', 'ehi_y_ss_scoreb',\n",
    "                         'ALL_MEAN_GORT', 'ICE']]\n",
    "\n",
    "\n",
    "# UPPS / BIS+BAS\n",
    "temp = pd.read_csv('/users/jsh/data/IG/Demographic+Behavior/abcd_mhy02.txt', sep = '\\t')\n",
    "temp = temp.loc[temp['eventname'] == 'baseline_year_1_arm_1']\n",
    "temp = temp[['subjectkey', 'upps_y_ss_negative_urgency', 'upps_y_ss_lack_of_planning', 'upps_y_ss_sensation_seeking',\n",
    "             'upps_y_ss_positive_urgency', 'upps_y_ss_lack_of_perseverance',\n",
    "             'bis_y_ss_bism_sum', 'bis_y_ss_basm_rr', 'bis_y_ss_basm_drive']]\n",
    "\n",
    "\n",
    "data_final = pd.merge(data_final, temp, how = 'inner', on = 'subjectkey')\n",
    "data_final['upps_y_ss_negative_urgency'] = data_final['upps_y_ss_negative_urgency'].astype(float)\n",
    "data_final['upps_y_ss_lack_of_planning'] = data_final['upps_y_ss_lack_of_planning'].astype(float)\n",
    "data_final['upps_y_ss_sensation_seeking'] = data_final['upps_y_ss_sensation_seeking'].astype(float)\n",
    "data_final['upps_y_ss_positive_urgency'] = data_final['upps_y_ss_positive_urgency'].astype(float)\n",
    "data_final['upps_y_ss_lack_of_perseverance'] = data_final['upps_y_ss_lack_of_perseverance'].astype(float)\n",
    "data_final['bis_y_ss_bism_sum'] = data_final['bis_y_ss_bism_sum'].astype(float)\n",
    "data_final['bis_y_ss_basm_rr'] = data_final['bis_y_ss_basm_rr'].astype(float)\n",
    "data_final['bis_y_ss_basm_drive'] = data_final['bis_y_ss_basm_drive'].astype(float)\n",
    "\n",
    "data_final['exclude'] = False\n",
    "data_train = data_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fMRI\n",
    "\n",
    "inputdir = '/users/jsh/data/IG/ICA/2023-04-25/input_valid'\n",
    "HC_target = os.listdir(inputdir + '/control')\n",
    "ADHD_target = os.listdir(inputdir + '/ADHD')\n",
    "\n",
    "j = 0\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Start\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i in tqdm_notebook(HC_target):\n",
    "    \n",
    "    sample = pd.read_csv(inputdir + '/control/' + i + '/fMRI/smooth8_within.txt', header = None)[0].tolist()\n",
    "    \n",
    "    if j == 0:\n",
    "        base = pd.DataFrame(sample)\n",
    "    else:\n",
    "        base['{}'.format(j)] = sample\n",
    "    j = j+1\n",
    "\n",
    "for i in tqdm_notebook(ADHD_target):\n",
    "    \n",
    "    sample = pd.read_csv(inputdir + '/ADHD/' + i + '/fMRI/smooth8_within.txt', header = None)[0].tolist()\n",
    "    \n",
    "    if j == 0:\n",
    "        base = pd.DataFrame(sample)\n",
    "    else:\n",
    "        base['{}'.format(j)] = sample\n",
    "    j = j+1\n",
    "    \n",
    "fMRI_X = base\n",
    "fMRI_X = np.transpose(fMRI_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gene validation dataset\n",
    "\n",
    "inputdir = '/users/jsh/data/IG/ICA/2023-04-25/input_valid'\n",
    "HC_target = os.listdir(inputdir + '/control')\n",
    "ADHD_target = os.listdir(inputdir + '/ADHD')\n",
    "\n",
    "j = 0\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Start\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i in tqdm_notebook(HC_target):\n",
    "    \n",
    "    sample = pd.read_csv(inputdir + '/control/' + i + '/Gene/gtex_v7_Brain_Nucleus_accumbens_basal_ganglia_predicted_expression.txt', header = None)[0].tolist()\n",
    "    \n",
    "    if j == 0:\n",
    "        base = pd.DataFrame(sample)\n",
    "    else:\n",
    "        temp = pd.DataFrame(sample)\n",
    "        base['{}'.format(j)] = temp\n",
    "    j = j+1\n",
    "\n",
    "for i in tqdm_notebook(ADHD_target):\n",
    "    \n",
    "    sample = pd.read_csv(inputdir + '/ADHD/' + i + '/Gene/gtex_v7_Brain_Nucleus_accumbens_basal_ganglia_predicted_expression.txt', header = None)[0].tolist()\n",
    "    \n",
    "    if j == 0:\n",
    "        base = pd.DataFrame(sample)\n",
    "    else:\n",
    "        temp = pd.DataFrame(sample)\n",
    "        base['{}'.format(j)] = temp\n",
    "    j = j+1\n",
    "    \n",
    "Gene_X = base\n",
    "Gene_X = np.transpose(Gene_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fMRI_S_list = [i for i in os.listdir('/users/jsh/data/IG/ICA/2023-04-25/pca_ref/result_nucleus/30') if '.img' in i]\n",
    "fMRI_S_list.remove('first_para_ica_comp_feature_1_load_coeff_.img')\n",
    "fMRI_S_list.remove('first_para_ica_comp_feature_2_load_coeff_.img')\n",
    "\n",
    "j = 0\n",
    "\n",
    "for i in fMRI_S_list:\n",
    "    mask = nib.load(\"/users/jsh/data/IG/mask/SST_group_dilate-1.nii\")\n",
    "    mask_np = np.array(mask.get_fdata())\n",
    "    \n",
    "    temp = nib.load('/users/jsh/data/IG/ICA/2023-04-25/pca_ref/result_nucleus/30/' + i)\n",
    "    temp = np.array(temp.get_fdata())[np.where(mask_np == 1)]\n",
    "    if j == 0:\n",
    "        base = pd.DataFrame(temp)\n",
    "    else:\n",
    "        base['{}'.format(j)] = temp\n",
    "    j = j + 1\n",
    "    \n",
    "fMRI_S = base.transpose()\n",
    "\n",
    "###\n",
    "\n",
    "Gene_S_list = [i for i in os.listdir('/users/jsh/data/IG/ICA/2023-04-25/pca_ref/result_nucleus/30') if '.asc' in i]\n",
    "\n",
    "j = 0\n",
    "\n",
    "for i in Gene_S_list:\n",
    "    temp = pd.read_csv('/users/jsh/data/IG/ICA/2023-04-25/pca_ref/result_nucleus/30/' + i, header = None)[0]\n",
    "    if j == 0:\n",
    "        base = pd.DataFrame(temp)\n",
    "    else:\n",
    "        base['{}'.format(j)] = temp\n",
    "    j = j + 1\n",
    "Gene_S = base.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fMRI component\n",
    "fMRI_A = np.dot(np.array(fMRI_X), np.linalg.pinv(np.array(fMRI_S))) # A = X * S-1\n",
    "fMRI_A_df = pd.DataFrame(fMRI_A)\n",
    "\n",
    "# Gene component\n",
    "Gene_A = np.dot(np.array(Gene_X), np.linalg.pinv(np.array(Gene_S)))\n",
    "Gene_A_df = pd.DataFrame(Gene_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdir = '/users/jsh/data/IG/ICA/2023-04-25/input_valid'\n",
    "HC_target = os.listdir(inputdir + '/control')\n",
    "ADHD_target = os.listdir(inputdir + '/ADHD')\n",
    "valid_target = HC_target + ADHD_target\n",
    "\n",
    "sbjlist = []\n",
    "\n",
    "for i in valid_target:\n",
    "    sbjlist.append(i[:4] + '_' + i[4:])\n",
    "    \n",
    "demo = pd.read_csv('/users/jsh/data/IG/Demographic+Behavior/abcd_sst02.txt', sep = '\\t')\n",
    "demo = demo.loc[demo['subjectkey'].isin(sbjlist)]\n",
    "demo = demo.loc[demo['eventname'] == 'baseline_year_1_arm_1']\n",
    "\n",
    "scanner = pd.read_csv('/users/jsh/data/IG/Demographic+Behavior/abcd_mri01.txt', sep = '\\t')\n",
    "scanner = scanner.loc[scanner['subjectkey'].isin(sbjlist)]\n",
    "\n",
    "demo_scanner = pd.merge(demo, scanner, on = 'subjectkey')\n",
    "\n",
    "demo_exclude = demo_scanner[['subjectkey', 'interview_age_x', 'sex', 'mri_info_manufacturer']]\n",
    "\n",
    "# handness\n",
    "temp = pd.read_csv('/users/jsh/data/IG/Demographic+Behavior/abcd_ehis01.txt', sep = '\\t')\n",
    "temp = temp[['subjectkey', 'ehi_y_ss_scoreb']]\n",
    "demo_exclude = pd.merge(demo_exclude, temp)\n",
    "\n",
    "demo_exclude['ehi_y_ss_scoreb'] = demo_exclude['ehi_y_ss_scoreb'].astype(float)\n",
    "\n",
    "\n",
    "# Genetic batch effect\n",
    "batch = pd.read_csv('/data5/open_data/ABCD/3.0/genomics_sample03/ABCD_release3.0_.batch_info.txt', sep = '\\t')\n",
    "batch = batch[['abcd.id_redcap', 'BATCH']]\n",
    "batch.columns = ['subjectkey', 'BATCH']\n",
    "demo_exclude = pd.merge(demo_exclude, batch)\n",
    "\n",
    "###\n",
    "\n",
    "basedir = '/users/jsh/data/IG/ICA/2023-04-25/input_valid'\n",
    "control_dir = basedir + '/control'\n",
    "ADHD_dir = basedir + '/ADHD'\n",
    "\n",
    "control_subjects = os.listdir(control_dir)\n",
    "ADHD_subjects = os.listdir(ADHD_dir)\n",
    "\n",
    "both_run = []\n",
    "run1 = []\n",
    "run2 = []\n",
    "\n",
    "for i in control_subjects:\n",
    "    targetdir = control_dir + '/' + i + '/fMRI'\n",
    "    if 'con_not_masked1.nii' and 'con_not_masked2.nii' in os.listdir(targetdir):\n",
    "        both_run.append(i[:4] + '_' + i[4:])\n",
    "    elif 'con_not_masked1.nii' in os.listdir(targetdir):\n",
    "        run1.append(i[:4] + '_' + i[4:])\n",
    "    elif 'con_not_masked2.nii' in os.listdir(targetdir):\n",
    "        run2.append(i[:4] + '_' + i[4:])\n",
    "        \n",
    "for i in ADHD_subjects:\n",
    "    targetdir = ADHD_dir + '/' + i + '/fMRI'\n",
    "    if 'con_not_masked1.nii' and 'con_not_masked2.nii' in os.listdir(targetdir):\n",
    "        both_run.append(i[:4] + '_' + i[4:])\n",
    "    elif 'con_not_masked1.nii' in os.listdir(targetdir):\n",
    "        run1.append(i[:4] + '_' + i[4:])\n",
    "    elif 'con_not_masked2.nii' in os.listdir(targetdir):\n",
    "        run2.append(i[:4] + '_' + i[4:])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/users/jsh/data/IG/Demographic+Behavior/abcd_sst02.txt', sep = '\\t')\n",
    "\n",
    "data = data.drop(['collection_id', 'abcd_sst02_id', 'dataset_id', 'src_subject_id', 'interview_date', 'collection_title'], axis = 1)\n",
    "data = data.loc[data['eventname'] == 'baseline_year_1_arm_1']\n",
    "data = data.drop(['eventname'], axis = 1)\n",
    "\n",
    "sbj_list = sbjlist\n",
    "\n",
    "sbj_info = pd.DataFrame()\n",
    "sbj_info['subjectkey'] = sbjlist\n",
    "\n",
    "data_merged = pd.merge(sbj_info, data, how = 'inner', on = 'subjectkey')\n",
    "\n",
    "data_merged['fMRI'] = fMRI_A_df[14 - 1]\n",
    "data_merged['Gene'] = Gene_A_df[21 - 1]\n",
    "\n",
    "data_merged.loc[data_merged['subjectkey'].isin(run1), 'tfmri_sst_all_beh_crgo_rt'] = data_merged[data_merged['subjectkey'].isin(run1)]['tfmri_sst_r1_beh_crgo_rt'].tolist()\n",
    "data_merged.loc[data_merged['subjectkey'].isin(run1), 'tfmri_sst_all_beh_crgo_mrt'] = data_merged[data_merged['subjectkey'].isin(run1)]['tfmri_sst_r1_beh_crgo_mrt'].tolist()\n",
    "data_merged.loc[data_merged['subjectkey'].isin(run1), 'tfmri_sst_all_beh_incrs_mrt'] = data_merged[data_merged['subjectkey'].isin(run1)]['tfmri_sst_r1_beh_incrs_mrt'].tolist()\n",
    "data_merged.loc[data_merged['subjectkey'].isin(run1), 'tfmri_sst_all_beh_crgo_stdrt'] = data_merged[data_merged['subjectkey'].isin(run1)]['tfmri_sst_r1_beh_crgo_stdrt'].tolist()\n",
    "\n",
    "data_merged = data_merged.astype({'tfmri_sst_all_beh_crgo_rt':'float',\n",
    "                                 'tfmri_sst_all_beh_crgo_mrt':'float',\n",
    "#                                  'tfmri_sst_all_beh_incrs_rt':'float',\n",
    "                                 'tfmri_sst_all_beh_incrs_mrt':'float',\n",
    "                                 'tfmri_sst_all_beh_tot_mssd':'float',\n",
    "                                 'tfmri_sst_all_beh_total_mssrt':'float',\n",
    "                                 'tfmri_sst_all_beh_total_issrt':'float',\n",
    "                                 'tfmri_sst_all_beh_crgo_stdrt':'float',\n",
    "                                 'tfmri_sst_all_beh_go_nt':'float',\n",
    "                                 'tfmri_sst_r1_beh_go_nt':'float',\n",
    "                                 'tfmri_sst_all_beh_crgo_nt':'float', # all correct go\n",
    "                                 'tfmri_sst_r1_beh_crgo_nt':'float', # r1 correct go\n",
    "                                 'tfmri_sst_all_beh_incrgo_nt':'float', # all incorrect go\n",
    "                                 'tfmri_sst_r1_beh_incrgo_nt':'float'}) # r1 incorrect go\n",
    "\n",
    "data_final = pd.merge(data_merged, demo_exclude, on = 'subjectkey')\n",
    "\n",
    "data_final['interview_age'] = data_final['interview_age'].astype(float)\n",
    "\n",
    "data_final.loc[data_final['subjectkey'].isin(run1), 'tfmri_sst_all_beh_crgo_nt'] = data_final[data_final['subjectkey'].isin(run1)]['tfmri_sst_r1_beh_crgo_nt'].tolist()\n",
    "data_final.loc[data_final['subjectkey'].isin(run1), 'tfmri_sst_all_beh_incrgo_nt'] = data_final[data_final['subjectkey'].isin(run1)]['tfmri_sst_r1_beh_incrgo_nt'].tolist()\n",
    "\n",
    "data_final['ALL_MEAN_GORT'] = (data_final['tfmri_sst_all_beh_crgo_mrt'] * data_final['tfmri_sst_all_beh_crgo_nt'] + data_final['tfmri_sst_all_beh_incrs_mrt'] * data_final['tfmri_sst_all_beh_incrgo_nt']) / (data_final['tfmri_sst_all_beh_crgo_nt'] + data_final['tfmri_sst_all_beh_incrgo_nt'])\n",
    "data_final['ICE'] = data_final['tfmri_sst_all_beh_total_mssrt'] - data_final['tfmri_sst_all_beh_tot_mssd']\n",
    "\n",
    "iq = pd.read_csv('/users/jsh/data/IG/Demographic+Behavior/abcd_tbss01.txt', sep = '\\t')\n",
    "iq = iq[['subjectkey', 'nihtbx_totalcomp_uncorrected']]\n",
    "data_final = pd.merge(data_final, iq, on = 'subjectkey')\n",
    "data_final = data_final.astype({'nihtbx_totalcomp_uncorrected':'float'})\n",
    "data_final['sex'] = data_final['sex_x']\n",
    "\n",
    "data_final['case'] = ['control'] * 200 + ['ADHD'] * 79\n",
    "\n",
    "data_final = data_final[['case', 'subjectkey', 'interview_age', 'sex', 'mri_info_manufacturer', 'BATCH', 'fMRI', 'Gene',\n",
    "                         'tfmri_sst_all_beh_crgo_rt', 'tfmri_sst_all_beh_crgo_mrt', 'tfmri_sst_all_beh_incrs_mrt',\n",
    "                         'tfmri_sst_all_beh_tot_mssd', 'tfmri_sst_all_beh_total_mssrt', \n",
    "                         'tfmri_sst_all_beh_total_issrt', 'tfmri_sst_all_beh_crgo_stdrt',\n",
    "                         'nihtbx_totalcomp_uncorrected',\n",
    "                         'ALL_MEAN_GORT', 'ICE', 'ehi_y_ss_scoreb']]\n",
    "\n",
    "# UPPS / BIS+BAS\n",
    "temp = pd.read_csv('/users/jsh/data/IG/Demographic+Behavior/abcd_mhy02.txt', sep = '\\t')\n",
    "temp = temp.loc[temp['eventname'] == 'baseline_year_1_arm_1']\n",
    "temp = temp[['subjectkey', 'upps_y_ss_negative_urgency', 'upps_y_ss_lack_of_planning', 'upps_y_ss_sensation_seeking',\n",
    "             'upps_y_ss_positive_urgency', 'upps_y_ss_lack_of_perseverance',\n",
    "             'bis_y_ss_bism_sum', 'bis_y_ss_basm_rr', 'bis_y_ss_basm_drive']]\n",
    "\n",
    "data_final = pd.merge(data_final, temp, how = 'inner', on = 'subjectkey')\n",
    "data_final['upps_y_ss_negative_urgency'] = data_final['upps_y_ss_negative_urgency'].astype(float)\n",
    "data_final['upps_y_ss_lack_of_planning'] = data_final['upps_y_ss_lack_of_planning'].astype(float)\n",
    "data_final['upps_y_ss_sensation_seeking'] = data_final['upps_y_ss_sensation_seeking'].astype(float)\n",
    "data_final['upps_y_ss_positive_urgency'] = data_final['upps_y_ss_positive_urgency'].astype(float)\n",
    "data_final['upps_y_ss_lack_of_perseverance'] = data_final['upps_y_ss_lack_of_perseverance'].astype(float)\n",
    "data_final['bis_y_ss_bism_sum'] = data_final['bis_y_ss_bism_sum'].astype(float)\n",
    "data_final['bis_y_ss_basm_rr'] = data_final['bis_y_ss_basm_rr'].astype(float)\n",
    "data_final['bis_y_ss_basm_drive'] = data_final['bis_y_ss_basm_drive'].astype(float)\n",
    "\n",
    "data_test = data_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_list = ['tfmri_sst_all_beh_crgo_rt', 'tfmri_sst_all_beh_crgo_mrt', 'tfmri_sst_all_beh_incrs_mrt', 'tfmri_sst_all_beh_tot_mssd',\n",
    "                 'tfmri_sst_all_beh_total_mssrt', 'tfmri_sst_all_beh_total_issrt', 'tfmri_sst_all_beh_crgo_stdrt', 'ALL_MEAN_GORT',\n",
    "                 'nihtbx_totalcomp_uncorrected', 'upps_y_ss_negative_urgency', 'upps_y_ss_positive_urgency', 'upps_y_ss_lack_of_perseverance',\n",
    "                 'upps_y_ss_lack_of_planning', 'upps_y_ss_sensation_seeking', 'bis_y_ss_bism_sum', 'bis_y_ss_basm_rr', 'bis_y_ss_basm_drive']\n",
    "\n",
    "for behavior in behavior_list:\n",
    "    print(behavior)\n",
    "    print(pg.ttest(data_test.loc[data_test['case'] == 'control'][behavior], data_test.loc[data_test['case'] == 'ADHD'][behavior]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for behavior in behavior_list:\n",
    "    \n",
    "    cor_var = []\n",
    "\n",
    "    # Train\n",
    "    data_train['fMRI_Gene'] = data_train['fMRI'] * data_train['Gene']\n",
    "    \n",
    "    data_final_HC = data_train.loc[data_train['case'] == 'control']\n",
    "    data_final_HC['exclude'] = False\n",
    "    data_final_ADHD = data_train.loc[data_train['case'] == 'ADHD']\n",
    "    data_final_ADHD['exclude'] = False\n",
    "    \n",
    "    #\n",
    "    mad = data_final_HC[['fMRI']].apply(robust.mad)['fMRI']\n",
    "    data_final_HC.loc[data_final_HC['fMRI'] > np.median(data_final_HC['fMRI']) + 3 * mad, 'exclude'] = True\n",
    "    data_final_HC.loc[data_final_HC['fMRI'] < np.median(data_final_HC['fMRI']) - 3 * mad, 'exclude'] = True\n",
    "\n",
    "    mad = data_final_HC[['Gene']].apply(robust.mad)['Gene']\n",
    "    data_final_HC.loc[data_final_HC['Gene'] > np.median(data_final_HC['Gene']) + 3 * mad, 'exclude'] = True\n",
    "    data_final_HC.loc[data_final_HC['Gene'] < np.median(data_final_HC['Gene']) - 3 * mad, 'exclude'] = True\n",
    "    \n",
    "    mad = data_final_HC[[behavior]].apply(robust.mad)[behavior]\n",
    "    data_final_HC.loc[data_final_HC[behavior] > np.median(data_final_HC[behavior]) + 3 * mad, 'exclude'] = True\n",
    "    data_final_HC.loc[data_final_HC[behavior] < np.median(data_final_HC[behavior]) - 3 * mad, 'exclude'] = True\n",
    "    \n",
    "    #\n",
    "    mad = data_final_ADHD[['fMRI']].apply(robust.mad)['fMRI']\n",
    "    data_final_ADHD.loc[data_final_ADHD['fMRI'] > np.median(data_final_ADHD['fMRI']) + 3 * mad, 'exclude'] = True\n",
    "    data_final_ADHD.loc[data_final_ADHD['fMRI'] < np.median(data_final_ADHD['fMRI']) - 3 * mad, 'exclude'] = True\n",
    "\n",
    "    mad = data_final_ADHD[['Gene']].apply(robust.mad)['Gene']\n",
    "    data_final_ADHD.loc[data_final_ADHD['Gene'] > np.median(data_final_ADHD['Gene']) + 3 * mad, 'exclude'] = True\n",
    "    data_final_ADHD.loc[data_final_ADHD['Gene'] < np.median(data_final_ADHD['Gene']) - 3 * mad, 'exclude'] = True\n",
    "    \n",
    "    mad = data_final_ADHD[[behavior]].apply(robust.mad)[behavior]\n",
    "    data_final_ADHD.loc[data_final_ADHD[behavior] > np.median(data_final_ADHD[behavior]) + 3 * mad, 'exclude'] = True\n",
    "    data_final_ADHD.loc[data_final_ADHD[behavior] < np.median(data_final_ADHD[behavior]) - 3 * mad, 'exclude'] = True   \n",
    "    \n",
    "    ####\n",
    "    data_final_HC = data_final_HC.drop(data_final_HC[data_final_HC['exclude'] == True].index)\n",
    "    data_final_ADHD = data_final_ADHD.drop(data_final_ADHD[data_final_ADHD['exclude'] == True].index)\n",
    "    \n",
    "    data_final_ = pd.concat([data_final_HC, data_final_ADHD])\n",
    "        \n",
    "    ####\n",
    "    data_target = data_final_HC\n",
    "\n",
    "    data_target = data_target[['fMRI', 'Gene', 'sex', 'interview_age','mri_info_manufacturer', 'BATCH', behavior, 'fMRI_Gene']]\n",
    "    data_target = data_target.dropna(axis = 0)\n",
    "    \n",
    "    \n",
    "    # log transform\n",
    "    statistic, p_value = skewtest(data_target[behavior])\n",
    "    if p_value < 0.05:\n",
    "        if behavior=='tfmri_sst_all_beh_crgo_rt':\n",
    "            data_target[behavior] = np.arcsin(np.sqrt(data_target[behavior]))\n",
    "        else:\n",
    "            data_target[behavior] = np.log1p(data_target[behavior])\n",
    "        print(behavior, \" is skewed!!!!\")\n",
    "        is_skew = True\n",
    "    else:\n",
    "        is_skew = False \n",
    "        \n",
    "    # For partial_corr\n",
    "    data_par = pd.get_dummies(data_target, columns = ['sex', 'mri_info_manufacturer', 'BATCH'])\n",
    "    cov_col = data_par.columns.tolist()\n",
    "    cov_col.remove('fMRI')\n",
    "    cov_col.remove('Gene')\n",
    "    cov_col.remove('fMRI_Gene')\n",
    "    cov_col.remove(behavior) \n",
    "    cor_var.extend([pg.partial_corr(data = data_par, x = 'fMRI', y = behavior, covar = cov_col)['r'][0],\n",
    "                  pg.partial_corr(data = data_par, x = 'fMRI', y = behavior, covar = cov_col)['p-val'][0],\n",
    "                  pg.partial_corr(data = data_par, x = 'Gene', y = behavior, covar = cov_col)['r'][0],\n",
    "                  pg.partial_corr(data = data_par, x = 'Gene', y = behavior, covar = cov_col)['p-val'][0]])\n",
    "    \n",
    "    \n",
    "    ####    \n",
    "    y_train = data_target[behavior].values\n",
    "    \n",
    "    X_train_o = data_target[['mri_info_manufacturer', 'BATCH']]\n",
    "    X_train_os = data_target[['sex']]    \n",
    "\n",
    "    X_base_train_s = data_target[['interview_age']]\n",
    "    X_fmri_train_s = data_target[['fMRI', 'interview_age']]\n",
    "    X_gene_train_s = data_target[['Gene', 'interview_age']]\n",
    "    X_both_train_s = data_target[['fMRI', 'Gene', 'interview_age']]\n",
    "    X_med_train_s = data_target[['fMRI', 'Gene', 'fMRI_Gene', 'interview_age']]\n",
    "\n",
    "    scaler_base = StandardScaler() \n",
    "    scaler_fmri = StandardScaler()\n",
    "    scaler_gene = StandardScaler()\n",
    "    scaler_both = StandardScaler()\n",
    "    scaler_med = StandardScaler()\n",
    "    \n",
    "    one_en = OneHotEncoder()\n",
    "    one_sex = OneHotEncoder(drop = 'first')\n",
    "    \n",
    "    X_train_o = one_en.fit_transform(X_train_o)\n",
    "    X_train_os = one_sex.fit_transform(X_train_os)    \n",
    "    \n",
    "    X_base_train_s = scaler_base.fit_transform(X_base_train_s)\n",
    "    X_base_train = np.concatenate([X_base_train_s, X_train_o.toarray(), X_train_os.toarray()], axis = 1)   \n",
    "    \n",
    "    X_fmri_train_s = scaler_fmri.fit_transform(X_fmri_train_s)\n",
    "    X_fmri_train = np.concatenate([X_fmri_train_s, X_train_o.toarray(), X_train_os.toarray()], axis = 1)\n",
    "\n",
    "    X_gene_train_s = scaler_gene.fit_transform(X_gene_train_s)\n",
    "    X_gene_train = np.concatenate([X_gene_train_s, X_train_o.toarray(), X_train_os.toarray()], axis = 1)\n",
    "    \n",
    "    X_both_train_s = scaler_both.fit_transform(X_both_train_s)\n",
    "    X_both_train = np.concatenate([X_both_train_s, X_train_o.toarray(), X_train_os.toarray()], axis = 1)\n",
    "    \n",
    "    X_med_train_s = scaler_med.fit_transform(X_med_train_s)\n",
    "    X_med_train = np.concatenate([X_med_train_s, X_train_o.toarray(), X_train_os.toarray()], axis = 1)    \n",
    "    \n",
    "    ####\n",
    "    alphas = np.logspace(-3, 3, 100)\n",
    "    \n",
    "    param_grid = {\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'epsilon': [0.01, 0.1, 0.2, 0.3]\n",
    "    }\n",
    "\n",
    "#     lr_base = LinearRegression()\n",
    "    lr_base = RidgeCV(alphas = alphas, cv = 5)\n",
    "    lr_base.fit(X_base_train, y_train)\n",
    "    \n",
    "    lr_fmri = RidgeCV(alphas = alphas, cv = 5)\n",
    "    lr_fmri.fit(X_fmri_train, y_train)\n",
    "    \n",
    "    lr_gene = RidgeCV(alphas = alphas, cv = 5)\n",
    "    lr_gene.fit(X_gene_train, y_train) \n",
    "    \n",
    "    lr_both = RidgeCV(alphas = alphas, cv = 5)\n",
    "    lr_both.fit(X_both_train, y_train)\n",
    "    \n",
    "    lr_med = RidgeCV(alphas = alphas, cv = 5)\n",
    "    lr_med.fit(X_med_train, y_train)\n",
    "\n",
    "    ####\n",
    "    # Test\n",
    "    data_test['fMRI_Gene'] = data_test['fMRI'] * data_test['Gene']\n",
    "    \n",
    "    data_final_HC = data_test.loc[data_test['case'] == 'control']\n",
    "    data_final_HC['exclude'] = False\n",
    "\n",
    "    data_final_ADHD = data_test.loc[data_test['case'] == 'ADHD']\n",
    "    data_final_ADHD['exclude'] = False\n",
    "    \n",
    "    #\n",
    "    mad = data_final_HC[['fMRI']].apply(robust.mad)['fMRI']\n",
    "    data_final_HC.loc[data_final_HC['fMRI'] > np.median(data_final_HC['fMRI']) + 3 * mad, 'exclude'] = True\n",
    "    data_final_HC.loc[data_final_HC['fMRI'] < np.median(data_final_HC['fMRI']) - 3 * mad, 'exclude'] = True\n",
    "\n",
    "    mad = data_final_HC[['Gene']].apply(robust.mad)['Gene']\n",
    "    data_final_HC.loc[data_final_HC['Gene'] > np.median(data_final_HC['Gene']) + 3 * mad, 'exclude'] = True\n",
    "    data_final_HC.loc[data_final_HC['Gene'] < np.median(data_final_HC['Gene']) - 3 * mad, 'exclude'] = True\n",
    "    \n",
    "    mad = data_final_HC[[behavior]].apply(robust.mad)[behavior]\n",
    "    data_final_HC.loc[data_final_HC[behavior] > np.median(data_final_HC[behavior]) + 3 * mad, 'exclude'] = True\n",
    "    data_final_HC.loc[data_final_HC[behavior] < np.median(data_final_HC[behavior]) - 3 * mad, 'exclude'] = True\n",
    "    \n",
    "    #\n",
    "    mad = data_final_ADHD[['fMRI']].apply(robust.mad)['fMRI']\n",
    "    data_final_ADHD.loc[data_final_ADHD['fMRI'] > np.median(data_final_ADHD['fMRI']) + 3 * mad, 'exclude'] = True\n",
    "    data_final_ADHD.loc[data_final_ADHD['fMRI'] < np.median(data_final_ADHD['fMRI']) - 3 * mad, 'exclude'] = True\n",
    "\n",
    "    mad = data_final_ADHD[['Gene']].apply(robust.mad)['Gene']\n",
    "    data_final_ADHD.loc[data_final_ADHD['Gene'] > np.median(data_final_ADHD['Gene']) + 3 * mad, 'exclude'] = True\n",
    "    data_final_ADHD.loc[data_final_ADHD['Gene'] < np.median(data_final_ADHD['Gene']) - 3 * mad, 'exclude'] = True\n",
    "    \n",
    "    mad = data_final_ADHD[[behavior]].apply(robust.mad)[behavior]\n",
    "    data_final_ADHD.loc[data_final_ADHD[behavior] > np.median(data_final_ADHD[behavior]) + 3 * mad, 'exclude'] = True\n",
    "    data_final_ADHD.loc[data_final_ADHD[behavior] < np.median(data_final_ADHD[behavior]) - 3 * mad, 'exclude'] = True   \n",
    "    \n",
    "    #\n",
    "    data_final_HC = data_final_HC.drop(data_final_HC[data_final_HC['exclude'] == True].index)\n",
    "    data_final_ADHD = data_final_ADHD.drop(data_final_ADHD[data_final_ADHD['exclude'] == True].index)\n",
    "    \n",
    "    data_final_ = pd.concat([data_final_HC, data_final_ADHD])    \n",
    "    \n",
    "    ####\n",
    "    data_target_test = data_final_HC\n",
    "\n",
    "    data_target_test = data_target_test[['fMRI', 'Gene', 'sex', 'interview_age', 'mri_info_manufacturer', 'BATCH', behavior, 'fMRI_Gene']]\n",
    "    data_target_test = data_target_test.dropna(axis = 0)\n",
    "    \n",
    "    \n",
    "    if is_skew:\n",
    "        if behavior=='tfmri_sst_all_beh_crgo_rt':\n",
    "            data_target_test[behavior] = np.arcsin(np.sqrt(data_target_test[behavior]))\n",
    "        else:\n",
    "            data_target_test[behavior] = np.log1p(data_target_test[behavior])\n",
    "            \n",
    "    # For partial_corr\n",
    "    data_par = pd.get_dummies(data_target_test, columns = ['sex', 'mri_info_manufacturer', 'BATCH'])\n",
    "    cov_col = data_par.columns.tolist()\n",
    "    cov_col.remove('fMRI')\n",
    "    cov_col.remove('Gene')\n",
    "    cov_col.remove('fMRI_Gene')\n",
    "    cov_col.remove(behavior)\n",
    "\n",
    "    cor_var.extend([pg.partial_corr(data = data_par, x = 'fMRI', y = behavior, covar = cov_col)['r'][0],\n",
    "                  pg.partial_corr(data = data_par, x = 'fMRI', y = behavior, covar = cov_col)['p-val'][0],\n",
    "                  pg.partial_corr(data = data_par, x = 'Gene', y = behavior, covar = cov_col)['r'][0],\n",
    "                  pg.partial_corr(data = data_par, x = 'Gene', y = behavior, covar = cov_col)['p-val'][0]])   \n",
    "    \n",
    "    ##\n",
    "    y_true = data_target_test[behavior].values\n",
    "    \n",
    "    X_test_o = data_target_test[['mri_info_manufacturer', 'BATCH']]\n",
    "    X_test_os = data_target_test[['sex']]    \n",
    "        \n",
    "    X_base_test_s = data_target_test[['interview_age']]\n",
    "    X_fmri_test_s = data_target_test[['fMRI', 'interview_age']]\n",
    "    X_gene_test_s = data_target_test[['Gene', 'interview_age']]\n",
    "    X_both_test_s = data_target_test[['fMRI', 'Gene', 'interview_age']]\n",
    "    X_med_test_s = data_target_test[['fMRI', 'Gene', 'fMRI_Gene', 'interview_age']]\n",
    "\n",
    "    #\n",
    "    X_test_o = one_en.transform(X_test_o)\n",
    "    X_test_os = one_sex.transform(X_test_os)    \n",
    "    \n",
    "    X_base_test_s = scaler_base.transform(X_base_test_s)\n",
    "    X_base_test = np.concatenate([X_base_test_s, X_test_o.toarray(), X_test_os.toarray()], axis = 1)    \n",
    "    \n",
    "    X_fmri_test_s = scaler_fmri.transform(X_fmri_test_s)\n",
    "    X_fmri_test = np.concatenate([X_fmri_test_s, X_test_o.toarray(), X_test_os.toarray()], axis = 1)\n",
    "\n",
    "    X_gene_test_s = scaler_gene.transform(X_gene_test_s)\n",
    "    X_gene_test = np.concatenate([X_gene_test_s, X_test_o.toarray(), X_test_os.toarray()], axis = 1)\n",
    "    \n",
    "    X_both_test_s = scaler_both.transform(X_both_test_s)\n",
    "    X_both_test = np.concatenate([X_both_test_s, X_test_o.toarray(), X_test_os.toarray()], axis = 1)\n",
    "    \n",
    "    X_med_test_s = scaler_med.fit_transform(X_med_test_s)\n",
    "    X_med_test = np.concatenate([X_med_test_s, X_test_o.toarray(), X_test_os.toarray()], axis = 1)      \n",
    "    \n",
    "    ###\n",
    "    y_base_pred = lr_base.predict(X_base_test)\n",
    "    y_fmri_pred = lr_fmri.predict(X_fmri_test)\n",
    "    y_gene_pred = lr_gene.predict(X_gene_test)\n",
    "    y_both_pred = lr_both.predict(X_both_test)\n",
    "    y_med_pred = lr_med.predict(X_med_test)\n",
    "    \n",
    "    y_true = y_true.reshape(-1)\n",
    "    y_fmri_pred = y_fmri_pred.reshape(-1)\n",
    "    y_gene_pred = y_gene_pred.reshape(-1)\n",
    "    y_both_pred = y_both_pred.reshape(-1)\n",
    "    y_med_pred = y_med_pred.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
